{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2016 term\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "0. [Overview](#Overview)\n",
    "0. [Set-up](#Set-up)\n",
    "0. [Working with SNLI](#Working-with-SNLI)\n",
    "   0. [Trees](#Trees)\n",
    "   0. [Readers](#Readers)\n",
    "0. [MaxEnt classifier approach](#MaxEnt-classifier-approach)\n",
    "   0. [Baseline classifier features](#Baseline-classifier-features)\n",
    "   0. [Classifier training and assessment](#Classifier-training-and-assessment)\n",
    "   0. [A few ideas for better classifier features](#A-few-ideas-for-better-classifier-features)\n",
    "0. [Recurrent neural network approach](#Shallow-neural-network-approach)\n",
    "0. [Some further reading](#Some-further-reading)\n",
    "0. [Exercises](#Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In the context of NLP/NLU, Natural Language Inference (NLI) is the task of predicting the logical relationships between words, phrases, sentences, (paragraphs, documents, ...). Such relationships are crucial for all kinds of reasoning in natural language: arguing, debating, problem solving, summarization, extrapolation, and so forth. \n",
    "\n",
    "NLI is a great task for this course. It requires serious linguistic analysis to do well, there are good publicly available datasets, and there are some natural baselines that help with getting a model up and running, and with understanding the performance of more sophisticated approaches.  NLI was also the topic of [Bill's thesis](http://nlp.stanford.edu/~wcmac/papers/nli-diss.pdf) (he popularized the name \"NLI\"), so you can forever endear yourself to him by working on it!\n",
    "\n",
    "We looked at NLI briefly in our word-level entailment bake-off (the `wordentail.ipynb` notebook). The purpose of this codebook is to introduce the problem of NLI more fully in the context of the [Stanford Natural Language Inference](http://nlp.stanford.edu/projects/snli/) corpus (SNLI). We'll explore two general approaches:\n",
    "\n",
    "* Standard classifiers\n",
    "* Recurrent neural networks\n",
    "\n",
    "This should be a good starting point for exploring richer models of NLI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Make sure your environment includes all the requirements for [the cs224u repository](https://github.com/cgpotts/cs224u), especially TensorFlow, which isn't included in the standard Anaconda distribution (but is [easily installed](https://anaconda.org/jjhelmus/tensorflow)).\n",
    "0. Make sure `snli_sample_src` is pointing to your copy of `semparse_dateparse_data.pickle`, which should be included in the repository in the `nli-data` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snli_sample_src = os.path.join('nli-data', 'snli_1.0_cs224u_sample.pickle')\n",
    "\n",
    "snli_sample = pickle.load(file(snli_sample_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import copy\n",
    "import pickle\n",
    "import codecs\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectFpr, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with SNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORD_RE = re.compile(r\"([^ \\(\\)]+)\", re.UNICODE)\n",
    "\n",
    "def str2tree(s):\n",
    "    \"\"\"Turns labeled bracketing s into a tree structure (tuple of tuples)\"\"\"\n",
    "    s = WORD_RE.sub(r'\"\\1\",', s)\n",
    "    s = s.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "    s = s.replace(\")\", \"),\").strip(\",\")\n",
    "    s = s.strip(\",\")\n",
    "    return eval(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For baseline models, we often want just the words, also called terminal nodes or _leaves_.\n",
    "This function gives us access to them as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('A', 'child'), ('is', ('playing', ('in', ('a', 'yard')))))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str2tree(\"( ( A child ) ( is ( playing ( in ( a yard ) ) ) ) )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaves(t):\n",
    "    \"\"\"Returns all of the words (terminal nodes) in tree t\"\"\"\n",
    "    words = []\n",
    "    for x in t:\n",
    "        if isinstance(x, basestring):\n",
    "            words.append(x)\n",
    "        else:\n",
    "            words += leaves(x)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'child', 'is', 'playing', 'in', 'a', 'yard']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaves(str2tree(\"( ( A child ) ( is ( playing ( in ( a yard ) ) ) ) )\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = ['entailment', 'contradiction', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def snli_reader():\n",
    "    for d in snli_sample:\n",
    "        yield (str2tree(d['sentence1_binary_parse']), \n",
    "               str2tree(d['sentence2_binary_parse']),\n",
    "               d['gold_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxEnt classifier approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classifier features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first baseline we define is the _word overlap_ baseline. It simply uses as\n",
    "features the words that appear in both sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_overlap_phi(t1, t2):\n",
    "    overlap = [w1 for w1 in leaves(t1) if w1 in leaves(t2)]\n",
    "    return Counter(overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular baseline is to use as features the full cross-product of\n",
    "words from both sentences:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_cross_product_phi(t1, t2):\n",
    "    return Counter([(w1, w2) for w1, w2 in itertools.product(leaves(t1), leaves(t2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these feature functions return count dictionaries mapping feature names to \n",
    "the number of times they occur in the data. This is the representation we'll work\n",
    "with throughout; scikit-learn will handle the further processing it needs to build\n",
    "linear classifiers.\n",
    "\n",
    "Naturally, you can do better than these feature functions! \n",
    "Both of these feature classes might be useful even in a more advanced model, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building datasets for experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in training a classifier is using a feature function like the one above\n",
    "to turn the data into a list of _training instances_: feature representations and their \n",
    "associated labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(reader=snli_reader, phi=word_overlap_phi):\n",
    "    feat_dicts = []\n",
    "    labels = []\n",
    "    raw_examples = []\n",
    "    for t1, t2, label in reader():\n",
    "        d = phi(t1, t2)\n",
    "        feat_dicts.append(d)\n",
    "        labels.append(label)   \n",
    "        raw_examples.append((t1, t2))\n",
    "    vectorizer = DictVectorizer(sparse=True)\n",
    "    feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "    return {'X': feat_matrix, \n",
    "            'y': labels, \n",
    "            'vectorizer': vectorizer, \n",
    "            'raw_examples': raw_examples}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(reader=snli_reader, phi=word_overlap_phi, cv=5):\n",
    "    dataset = build_dataset(reader, phi)\n",
    "    X = dataset['X']\n",
    "    y = np.array(dataset['y'])\n",
    "    mod = LogisticRegression(fit_intercept=True, C=1.0, penalty='l2')\n",
    "    for train_indices, assess_indices in KFold(len(y), n_folds=cv, shuffle=True):\n",
    "        X_train, y_train = X[train_indices], y[train_indices]        \n",
    "        X_assess, y_assess = X[assess_indices], y[assess_indices]\n",
    "        mod.fit(X_train, y_train)\n",
    "        predictions = mod.predict(X_assess)\n",
    "        print precision_recall_fscore_support(y_assess, predictions)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.42920682,  0.51626016,  0.39113924]), array([ 0.5899134 ,  0.43365854,  0.31102164]), array([ 0.49688908,  0.47136797,  0.34650967]), array([1963, 2050, 1987]))\n",
      "(array([ 0.43262136,  0.48258706,  0.40655941]), array([ 0.55783676,  0.43715573,  0.32751745]), array([ 0.48731409,  0.45874934,  0.36278299]), array([1997, 1997, 2006]))\n",
      "(array([ 0.43671608,  0.48146067,  0.40780365]), array([ 0.5640648 ,  0.43568887,  0.3246493 ]), array([ 0.49228792,  0.45743261,  0.36150628]), array([2037, 1967, 1996]))\n",
      "(array([ 0.43084502,  0.49662162,  0.38990536]), array([ 0.56736527,  0.44299347,  0.30822943]), array([ 0.48976955,  0.46827714,  0.34428969]), array([2004, 1991, 2005]))\n",
      "(array([ 0.42578424,  0.47314715,  0.37795276]), array([ 0.55677839,  0.44160401,  0.28713858]), array([ 0.48254932,  0.45683173,  0.32634561]), array([1999, 1995, 2006]))\n"
     ]
    }
   ],
   "source": [
    "experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few ideas for better classifier features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cross product of synsets compatible with each word, as given by WordNet. (Here is [a codebook on using WordNet from NLTK to do things like this](http://compprag.christopherpotts.net/wordnet.html).)\n",
    "\n",
    "* More fine-grained WordNet features &mdash; e.g., spotting pairs like _puppy_/_dog_ across the two sentences.\n",
    "\n",
    "* Use of other WordNet relations (see Table 1 and Table 2 in [the above codelab](http://compprag.christopherpotts.net/wordnet.html) for relations and their coverage).\n",
    "\n",
    "* Using the tree structure to define features that are sensitive to how negation scopes over constituents.\n",
    "\n",
    "* Features that are sensitive to differences in negation between the two sentences.\n",
    "\n",
    "* Sentiment features seeking to identify contrasting polarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Recurrent neural network approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bowman, Samuel R.; Christopher Potts; and Christopher D. Manning. 2014. \n",
    "[Recursive neural networks for learning logical semantics](http://arxiv.org/abs/1406.1827). \n",
    "arXiv manuscript 1406.1827. \n",
    "\n",
    "Dagan, Ido; Oren Glickman; and  Bernardo Magnini. 2006. \n",
    "[The PASCAL recognising textual entailment challenge](http://eprints.pascal-network.org/archive/00001298/01/dagan_et_al_rte05.pdf).\n",
    "In J. Quinonero-Candela, I. Dagan, B. Magnini, F. d'Alché-Buc, ed., _Machine Learning Challenges_, \n",
    "177-190. Springer-Verlag.\n",
    "\n",
    "Icard, Thomas F. 2012. [Inclusion and exclusion in natural language](http://link.springer.com/article/10.1007%2Fs11225-012-9425-8). _Studia Logica_ 100(4): 705-725.\n",
    "\n",
    "MacCartney, Bill and Christopher D. Manning. 2009. \n",
    "[An extended model of natural logic](http://www.aclweb.org/anthology/W09-3714). \n",
    "In  _Proceedings of the Eighth International Conference on Computational Semantics_, 140-156. \n",
    "Tilburg, The Netherlands: Association for Computational Linguistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
